#compdef pytest

# zsh completions for 'pytest'
# automatically generated with http://github.com/RobSis/zsh-completion-generator
local arguments

arguments=(
  '-k[only run tests which match the given substring]'
  '-m[only run tests matching given mark expression.]'
  '--markers[show markers (builtin, plugin and per-project ones).]'
  {-x,--exitfirst}'[exit instantly on first error or failed test.]'
  {--fixtures,--funcargs}'[show available fixtures, sorted by plugin appearance]'
  '--fixtures-per-test[show fixtures per test]'
  '--pdb[start the interactive Python debugger on errors or]'
  '--pdbcls[start a custom interactive Python debugger on errors.]'
  '--pdbcls[.terminal.debugger:TerminalPdb]'
  '--trace[immediately break when running each test.]'
  '--capture[per-test capturing method: one of fd|sys|no|tee-sys.]'
  '-s[shortcut for --capture=no.]'
  '--runxfail[report the results of xfail tests as if they were not]'
  {--lf,--last-failed}'[rerun only the tests that failed at the last run (or all]'
  {--ff,--failed-first}'[run all tests, but run the last failures first.]'
  {--nf,--new-first}'[run tests from new files first, then the rest of the]'
  '--cache-show[show cache contents, dont perform collection or tests.]'
  '--cache-clear[remove all cache contents at start of test run.]'
  '--lfnf[none}, --last-failed-no-failures={all,none}]'
  {--sw,--stepwise}'[exit on test failure and continue from last failing test]'
  {--sw-skip,--stepwise-skip}'[ignore the first failing test but stop on the next]'
  '--durations[show N slowest setup/test durations (N=0 for all).]'
  '--durations-min[minimal duration in seconds for inclusion in slowest]'
  {-v,--verbose}'[increase verbosity.]'
  '--no-header[disable header]'
  '--no-summary[disable summary]'
  {-q,--quiet}'[decrease verbosity.]'
  '--verbosity[set verbosity. Default is 0.]'
  '-r[show extra test summary info as specified by chars:]'
  '--disable-warnings[), N can be used to reset the list.]'
  {--disable-warnings,--disable-pytest-warnings}'[disable warnings summary]'
  {-l,--showlocals}'[show locals in tracebacks (disabled by default).]'
  '--tb[traceback print mode (auto/long/short/line/native/no).]'
  '--show-capture[stdout,stderr,log,all}]'
  '--full-trace[dont cut any tracebacks (default is to cut).]'
  '--color[color terminal output (yes/no/auto).]'
  '--code-highlight[no}]'
  '--pastebin[send failed|all info to bpaste.net pastebin service.]'
  '--junit-xml[create junit-xml style report file at given path.]'
  '--junit-prefix[prepend prefix to classnames in junit-xml output]'
  {-W,--pythonwarnings}'[set which warnings to report, see -W option of python]'
  '--maxfail[exit after first num failures or errors.]'
  '--strict-config[any warnings encountered while parsing the `pytest`]'
  '--strict-markers[markers not registered in the `markers` section of the]'
  '--strict[(deprecated) alias to --strict-markers.]'
  '-c[load configuration from `file` instead of trying to]'
  '--continue-on-collection-errors[force test execution even if collection errors occur.]'
  '--rootdir[define root directory for tests. Can be relative path:]'
  {--collect-only,--co}'[only collect tests, dont execute them.]'
  '--pyargs[try to interpret all arguments as python packages.]'
  '--ignore[ignore path during collection (multi-allowed).]'
  '--ignore-glob[ignore path pattern during collection (multi-allowed).]'
  '--deselect[deselect item (via node id prefix) during collection]'
  '--confcutdir[only load conftest.pys relative to specified dir.]'
  '--noconftest[dont load any conftest.py files.]'
  '--keep-duplicates[keep duplicate tests.]'
  '--collect-in-virtualenv[dont ignore tests in a local virtualenv directory]'
  '--import-mode[append,importlib}]'
  '--doctest-modules[run doctests in all .py modules]'
  '--doctest-report[cdiff,ndiff,udiff,only_first_failure}]'
  '--doctest-glob[doctests file matching pattern, default: test*.txt]'
  '--doctest-ignore-import-errors[ignore doctest ImportErrors]'
  '--doctest-continue-on-failure[for a given doctest, continue to run after the first]'
  '--basetemp[base temporary directory for this test run.(warning:]'
  {-V,--version}'[display pytest version and information about]'
  {-h,--help}'[show help message and configuration info]'
  '-p[early-load given plugin module name or entry point]'
  '--trace-config[trace considerations of conftest.py files.]'
  '--debug[store internal tracing debug information in]'
  {-o,--override-ini}'[override ini option with "option=value" style, e.g. `-o]'
  '--assert[control assertion debugging tools.]'
  '--setup-only[only setup fixtures, do not execute tests.]'
  '--setup-show[show setup of fixtures while executing tests.]'
  '--setup-plan[show what fixtures and tests would be executed but dont]'
  '--log-level[level of messages to catch/display.]'
  '--log-format[log format as used by the logging module.]'
  '--log-date-format[log date format as used by the logging module.]'
  '--log-cli-level[cli logging level.]'
  '--log-cli-format[log format as used by the logging module.]'
  '--log-cli-date-format[log date format as used by the logging module.]'
  '--log-file[path to a file when logging will be written to.]'
  '--log-file-level[log file logging level.]'
  '--log-file-format[log format as used by the logging module.]'
  '--log-file-date-format[log date format as used by the logging module.]'
  '--log-auto-indent[auto-indent multiline messages passed to the logging]'
  '--cov[path or package name to measure during execution (multi-]'
  '--cov-report[type of report to generate: term, term-missing]'
  '--cov-config[config file for coverage. Default: .coveragerc]'
  '--no-cov-on-fail[do not report coverage if test run fails. Default: False]'
  '--no-cov[disable coverage report completely (useful for]'
  '--cov-fail-under[fail if the total coverage is less than MIN.]'
  '--cov-append[do not delete coverage but append to current. Default:]'
  '--cov-branch[enable branch coverage.]'
  '--cov-context[dynamic contexts to use. "test" for now.]'
  '-W[/--pythonwarnings.]'
  '*:filename:_files'
)

_arguments -s $arguments
